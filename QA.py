# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UQi_le-AODBbsSgfp-xf4PPxkW5Y3TEs
"""

!pip install pymupdf faiss-cpu sentence-transformers opencv-python pillow
!apt-get install poppler-utils

!pip install pymupdf faiss-cpu

from google.colab import files
import os

os.makedirs("pdfs", exist_ok=True)
uploaded = files.upload()

for filename in uploaded.keys():
    os.rename(filename, os.path.join("pdfs", filename))

print("âœ… PDFs uploaded to /pdfs")

import fitz  # PyMuPDF
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from PIL import Image, ImageDraw
from IPython.display import display
import os

# Model
model = SentenceTransformer("clip-ViT-B-32")

# Text & Bounding Box Extraction
def extract_text_with_positions(pdf_path):
    doc = fitz.open(pdf_path)
    pages_data = []
    for i, page in enumerate(doc):
        blocks = page.get_text("blocks")  # (x0, y0, x1, y1, "text", block_no)
        for block in blocks:
            text = block[4].strip()
            if text:
                pages_data.append({
                    "text": text,
                    "page": i,
                    "bbox": (block[0], block[1], block[2], block[3])
                })
    return pages_data, doc

# Build FAISS index
def build_index(data):
    texts = [item["text"] for item in data]
    embeddings = model.encode(texts, convert_to_tensor=False, show_progress_bar=True)
    index = faiss.IndexFlatL2(len(embeddings[0]))
    index.add(np.array(embeddings))
    return index, texts, embeddings

# Search top answers
def get_best_answers(question, index, texts, embeddings, pages_data, top_k=1):
    q_embedding = model.encode([question])[0]
    D, I = index.search(np.array([q_embedding], dtype='float32'), top_k)
    results = []
    for idx in I[0]:
        if idx == -1:
            continue
        page_num = pages_data[idx]["page"]
        answer_text = pages_data[idx]["text"].strip()
        bbox = pages_data[idx]["bbox"]
        results.append({
            "page_number": page_num,
            "answer_text": answer_text,
            "bbox": bbox
        })
    return results

# Highlight Bounding Box on page screenshot
def highlight_text_on_page(doc, page_num, bbox):
    page = doc[page_num]
    pix = page.get_pixmap(dpi=150)
    img = Image.frombytes("RGB", [pix.width, pix.height], pix.samples)

    zoom_x = pix.width / page.rect.width
    zoom_y = pix.height / page.rect.height
    x0, y0, x1, y1 = bbox
    bbox_scaled = (x0 * zoom_x, y0 * zoom_y, x1 * zoom_x, y1 * zoom_y)

    draw = ImageDraw.Draw(img)
    draw.rectangle(bbox_scaled, outline="red", width=3)
    return img

# PDF Selector
pdf_files = sorted(os.listdir("pdfs"))
print("Available PDFs:")
for i, file in enumerate(pdf_files):
    print(f"{i+1}. {file}")

choice = int(input(" Choose a PDF number: ")) - 1
selected_pdf = os.path.join("pdfs", pdf_files[choice])

# Ask Question
question = input(" Ask your question: ")

# Run Pipeline
pages_data, doc = extract_text_with_positions(selected_pdf)
index, texts, embeddings = build_index(pages_data)
answers = get_best_answers(question, index, texts, embeddings, pages_data, top_k=1)

# Display Result
for ans in answers:
    print(f"\n Answer (Page {ans['page_number']+1}):\n{ans['answer_text']}")
    img = highlight_text_on_page(doc, ans["page_number"], ans["bbox"])
    display(img)